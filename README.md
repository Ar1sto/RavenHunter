# RavenHunter: CIA Document Scraping Tool

*RavenHunter* is a tool designed to scrape all available documents ever published by the CIA under the Freedom of Information Act (FOIA). This guide covers installation, usage, and additional notes for advanced users, including special considerations when scraping `.gov` websites.

---

## Table of Contents

1. [Installation](#installation)
2. [Usage](#usage)
3. [Advanced Usage](#advanced-usage)
4. [Notes on Scraping .gov Websites](#notes-on-scraping-gov-websites)
5. [Function Descriptions](#function-descriptions)
6. [Screenshots](#screenshots)
7. [License](#license)

---

## Installation

### Requirements

Before you begin, ensure you have Python 3.6+ installed. Then, install the required dependencies by running:

```bash
pip install -r requirements.txt
```

### Dependencies

- **requests**: HTTP requests library.
- **tqdm**: Progress bar library for Python.
- **colorama**: Cross-platform support for colored terminal text.
- **playwright**: For browser automation and scraping.
- **beautifulsoup4**: HTML parsing library for scraping and navigating web pages.

If you haven't already installed the necessary browsers for Playwright, run:

```bash
playwright install
```

This will install the required Chromium browser, as Playwright uses a headless browser to render pages for scraping.

---

## Usage

### Running the Script

You can start the script using the command line. Here are the available options:

```bash
python RavenHunter.py --help
```

### Example Usage

To begin scraping and storing found links, run:

```bash
python RavenHunter.py
```

For specific tasks, use the following flags:

- **Export found links**: 
    - Export links to a CSV or JSON file.
    - Example: 
    ```bash
    python RavenHunter.py --export json
    ```

- **Download found documents**: 
    - Download all documents found in the scraping process.
    - Example:
    ```bash
    python RavenHunter.py -dl
    ```

- **Resume scraping**: 
    - Resume the scraping from the last page saved.
    - Example:
    ```bash
    python RavenHunter.py --resume
    ```

### Command Line Options

| Option           | Description                                             |
|------------------|---------------------------------------------------------|
| `-dl`            | Downloads found documents.                             |
| `--timeout`      | Set timeout in seconds between page scrapes. (Default: 10) |
| `--resume`       | Resumes scraping from the last scraped page.            |
| `--export`       | Export found links to either CSV or JSON.               |
| `--verbose`      | Display links while scraping.                           |

---

## Advanced Usage

### Scraping Multiple Pages

The script is designed to scrape multiple pages of documents. It uses Playwright to automate browser interaction and BeautifulSoup for parsing the HTML content. If you wish to scrape from a specific page or control the process, you can modify the `resume_page` variable in the script.

### Exporting Found Links

If you wish to export the found links without scraping new data, you can use the `--export` flag. This will create a CSV or JSON file with all the links that have been previously scraped.

### Example Export Command

```bash
python RavenHunter.py --export csv
```

This command will generate a CSV file with all found links in the format:

```
Generated by *RavenHunter*

URL: https://www.cia.gov/readingroom/docs/CIA-RDP80B01676R000200020004-6.pdf
URL: https://www.cia.gov/readingroom/docs/CIA-RDP80B01676R000100150049-4.pdf
```

---

## Notes on Scraping `.gov` Websites

When scraping `.gov` websites, you must be mindful of the following:

1. **Respectful Usage**:
   - Avoid excessive scraping that can overload the server. Always use a reasonable `timeout` between requests (e.g., `30` seconds).
   - Check the site’s `robots.txt` file for any scraping restrictions.

2. **Legal Considerations**:
   - Ensure that your activities comply with local laws and government regulations when scraping publicly available data.
   - The Freedom of Information Act (FOIA) is often the basis for accessing documents from `.gov` domains, so make sure to follow the correct procedures.

3. **IP Blocking and Rate Limiting**:
   - Some government sites may implement rate-limiting mechanisms (e.g., CAPTCHAs) or even block IP addresses for suspicious activity. Be prepared to handle these scenarios and implement workarounds if needed. (TOR?, Proxy(rotation)?)

---

## Function Descriptions

### `init_db()`

- **Purpose**: Initializes the SQLite database used to track scraped links and pages.
- **Behavior**: Creates tables for storing found links and page numbers, ensuring the database schema is correct.

### `log_found(url)`

- **Purpose**: Logs a new document link in the `found_links` table of the database.
- **Behavior**: Stores the URL and timestamp of the document.

### `get_all_found_links()`

- **Purpose**: Retrieves all the links found and stored in the database.
- **Behavior**: Returns a list of URLs.

### `scrape_documents(timeout, resume_page, verbose, conn, c)`

- **Purpose**: The core function for scraping pages from the CIA’s website.
- **Behavior**: Scrapes pages, extracts document links, and stores them in the database.
- **Arguments**:
  - `timeout`: Time between scraping each page.
  - `resume_page`: Page number to resume scraping from.
  - `verbose`: Whether to display additional information during scraping.

### `export_found_links(format="json")`

- **Purpose**: Exports the found document links to a file.
- **Behavior**: Writes the links to either a JSON or CSV file, depending on the chosen format.

### `download_found_documents()`

- **Purpose**: Downloads all found documents as PDFs.
- **Behavior**: Downloads the PDF versions of the documents found and saves them to the local directory.

---

## Output

### 1. Scraping Output

```plaintext
[INFO] Found link: https://www.cia.gov/readingroom/docs/CIA-RDP80B01676R000200020004-6.pdf
[INFO] Found link: https://www.cia.gov/readingroom/docs/CIA-RDP80B01676R000100150049-4.pdf
[INFO] Found link: https://www.cia.gov/readingroom/docs/CIA-RDP80B01676R000100150040-3.pdf
```

### 2. Exported CSV File Example

```csv
Generated by *RavenHunter*

https://www.cia.gov/readingroom/docs/CIA-RDP80B01676R000200020004-6.pdf
https://www.cia.gov/readingroom/docs/CIA-RDP80B01676R000100150049-4.pdf
```

---

## License

RavenHunter is licensed under the MIT License. See the LICENSE file for more details.

---

**Note**: This tool is for educational and research purposes only. Always ensure you are adhering to all applicable laws and regulations when scraping or interacting with websites.
